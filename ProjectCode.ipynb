{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.xception import Xception\n",
    "from keras.models import load_model\n",
    "from tensorflow.python.keras.utils import get_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the directory containing the face images\n",
    "face_images_dir = \"path/to/face/images/directory\"\n",
    "\n",
    "# Download the Xception model weights if not already available\n",
    "xception_weights_path = get_file(\n",
    "    'xception_weights.h5',\n",
    "    'https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights.h5',\n",
    "    cache_subdir='models',\n",
    "    file_hash='b0042744bf5b25fce3cb969f33bebb97')\n",
    "\n",
    "# Path to the LQ model (EDSR)\n",
    "edsr_model_path = \"path/to/edsr_model.h5\"\n",
    "\n",
    "# Load the HQ model (Xception)\n",
    "hq_model = Xception(weights=xception_weights_path, include_top=False)\n",
    "\n",
    "# Load the LQ model (EDSR)\n",
    "lq_model = load_model(edsr_model_path)\n",
    "\n",
    "# Initialize the predictions dictionary\n",
    "predictions = {}\n",
    "\n",
    "# Iterate over the face images\n",
    "for filename in os.listdir(face_images_dir):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        image_path = os.path.join(face_images_dir, filename)\n",
    "        img = image.load_img(image_path, target_size=(224, 224))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = x / 255.0  # Normalize the image\n",
    "\n",
    "        # Make predictions using the HQ model (Xception)\n",
    "        hq_prediction = hq_model.predict(x)[0][0]\n",
    "\n",
    "        # Make predictions using the LQ model (EDSR)\n",
    "        lq_prediction = lq_model.predict(x)[0][0]\n",
    "\n",
    "        # Store the predictions in the dictionary\n",
    "        predictions[filename] = [hq_prediction, lq_prediction]\n",
    "\n",
    "# Update the sample sheet with the predicted probabilities\n",
    "sample_sheet = \"path/to/sample_sheet.csv\"\n",
    "\n",
    "with open(sample_sheet, 'r') as file:\n",
    "    csv_data = list(csv.reader(file))\n",
    "\n",
    "# Find the index of the \"predict\" column\n",
    "predict_index = csv_data[0].index(\"predict\")\n",
    "\n",
    "# Update the predicted probabilities in the sample sheet\n",
    "for row in csv_data[1:]:\n",
    "    filename = row[0]\n",
    "    if filename in predictions:\n",
    "        hq_prediction, lq_prediction = predictions[filename]\n",
    "        row[predict_index] = f\"HQ: {hq_prediction:.4f}, LQ: {lq_prediction:.4f}\"\n",
    "\n",
    "# Write the updated sample sheet with predicted probabilities\n",
    "with open(sample_sheet, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(csv_data)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
